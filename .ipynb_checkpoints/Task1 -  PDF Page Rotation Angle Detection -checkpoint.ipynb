{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf43550",
   "metadata": {},
   "source": [
    "## PDF Page Rotation Angle Detection Task\n",
    "\n",
    "Objective:\n",
    "Implement the `determine_rotation_angle` function within the given code structure to detect the rotation angle of each page in a PDF file.\n",
    "\n",
    "Code Structure:\n",
    "The main function `rotate_all_pages_upright` is already implemented, but if necessary you are allowed to change its implementation. Your task is to complete the `determine_rotation_angle` function.\n",
    "\n",
    "Input:\n",
    "- A PDF file path (the function should be able to handle various PDF files)\n",
    "\n",
    "Output:\n",
    "- A list of integers, where each integer represents the rotation angle needed for a page in the PDF\n",
    "\n",
    "Rotation Angle:\n",
    "- The rotation angle should be in degrees, normalized to the range [0, 359].\n",
    "- 0 means the page is already upright\n",
    "- 90 means the page needs to be rotated 90 degrees clockwise to be upright\n",
    "- and so on...\n",
    "\n",
    "Task:\n",
    "1. Implement the `determine_rotation_angle` function:\n",
    "   - Input: A single page object (PdfReader.PageObject)\n",
    "   - Output: An integer representing the rotation angle in degrees\n",
    "\n",
    "2. The function should analyze the content of the page and determine the angle needed to make the page upright.\n",
    "\n",
    "Requirements:\n",
    "1. The function should work with different PDF files, not just a specific one.\n",
    "2. Implement robust methods to determine the correct rotation angle.\n",
    "3. Handle potential exceptions or edge cases (e.g., pages with mixed orientations, complex layouts).\n",
    "4. Optimize for both accuracy and processing speed, as the function will be called for each page in the PDF.\n",
    "\n",
    "Additional Considerations:\n",
    "- You are allowed to use up to 40GB of GPU VRAM if necessary for your implementation.\n",
    "- You may create as many additional functions as needed to support your implementation.\n",
    "- You may use additional libraries if required, but ensure they are imported properly.\n",
    "- Provide clear comments in your code to explain your rotation detection logic.\n",
    "\n",
    "Testing:\n",
    "- Test your implementation with various types of PDFs to ensure its robustness and generalizability.\n",
    "- The main script provides a way to test your implementation on a file named \"grouped_documents.pdf\".\n",
    "\n",
    "Note:\n",
    "The task involves determining the rotation angle only. The actual rotation of the pages is not required in this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a0042f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation angles for each page: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "def rotate_all_pages_upright(input_pdf: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Analyze all pages in the input PDF and determine the rotation angle needed for each page.\n",
    "\n",
    "    Args:\n",
    "    input_pdf (str): The file path of the input PDF.\n",
    "\n",
    "    Returns:\n",
    "    List[int]: A list of rotation angles (in degrees) for each page. \n",
    "               The angles are normalized to be in the range [0, 359].\n",
    "               0 means no rotation needed, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf)\n",
    "    writer = PdfWriter()\n",
    "    \n",
    "    angles = []\n",
    "    for page_number in range(len(reader.pages)):\n",
    "        current_page = reader.pages[page_number]\n",
    "        \n",
    "        rotation_angle = determine_rotation_angle(current_page)\n",
    "        angles.append(rotation_angle)\n",
    "    \n",
    "    return angles\n",
    "\n",
    "def determine_rotation_angle(page: 'PdfReader.PageObject') -> int:\n",
    "    \"\"\"\n",
    "    Determine the rotation angle needed to make the page upright.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    int:  The rotation angle in degrees (e.g. 0, 90, 210).\n",
    "          The rotation angle is  normalized to be in the range [0, 359].\n",
    "          0 means the page is already upright, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    # TODO: Implement the logic to determine the rotation angle of the pdf page\n",
    "    return 0\n",
    "\n",
    "# Usage\n",
    "input_pdf: str = \"grouped_documents.pdf\"\n",
    "rotation_angles: List[int] = rotate_all_pages_upright(input_pdf)\n",
    "print(f\"Rotation angles for each page: {rotation_angles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bad6686",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x000001F273579AD0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 92\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[0;32m     91\u001b[0m input_pdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrouped_documents.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 92\u001b[0m rotation_angles \u001b[38;5;241m=\u001b[39m rotate_all_pages_upright(input_pdf)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRotation angles for each page: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrotation_angles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 23\u001b[0m, in \u001b[0;36mrotate_all_pages_upright\u001b[1;34m(input_pdf)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_number \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(reader\u001b[38;5;241m.\u001b[39mpages)):\n\u001b[0;32m     22\u001b[0m     current_page \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mpages[page_number]\n\u001b[1;32m---> 23\u001b[0m     rotation_angle \u001b[38;5;241m=\u001b[39m determine_rotation_angle(current_page)\n\u001b[0;32m     24\u001b[0m     angles\u001b[38;5;241m.\u001b[39mappend(rotation_angle)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m angles\n",
      "Cell \u001b[1;32mIn[5], line 40\u001b[0m, in \u001b[0;36mdetermine_rotation_angle\u001b[1;34m(page)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03mDetermine the rotation angle needed to make the page upright.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m      0 means the page is already upright, 90 means 90 degrees clockwise, etc.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Extract the text content of the page\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m text \u001b[38;5;241m=\u001b[39m extract_text_from_page(page)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m text\u001b[38;5;241m.\u001b[39mstrip():\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# If no text is found, assume the page is upright\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 62\u001b[0m, in \u001b[0;36mextract_text_from_page\u001b[1;34m(page)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03mExtract text from a PDF page using OCR.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03mstr: The extracted text content.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Convert the PDF page to an image\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m page_image \u001b[38;5;241m=\u001b[39m convert_pdf_page_to_image(page)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Use Tesseract to extract text from the image\u001b[39;00m\n\u001b[0;32m     65\u001b[0m text \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_string(page_image)\n",
      "Cell \u001b[1;32mIn[5], line 87\u001b[0m, in \u001b[0;36mconvert_pdf_page_to_image\u001b[1;34m(page)\u001b[0m\n\u001b[0;32m     84\u001b[0m pdf_bytes\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Convert the single-page PDF to an image using PIL\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(pdf_bytes)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\hiringstudy01\\Lib\\site-packages\\PIL\\Image.py:3498\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3496\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[0;32m   3497\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[1;32m-> 3498\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x000001F273579AD0>"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import io\n",
    "\n",
    "def rotate_all_pages_upright(input_pdf: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Analyze all pages in the input PDF and determine the rotation angle needed for each page.\n",
    "\n",
    "    Args:\n",
    "    input_pdf (str): The file path of the input PDF.\n",
    "\n",
    "    Returns:\n",
    "    List[int]: A list of rotation angles (in degrees) for each page. \n",
    "               The angles are normalized to be in the range [0, 359].\n",
    "               0 means no rotation needed, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf)\n",
    "    angles = []\n",
    "    for page_number in range(len(reader.pages)):\n",
    "        current_page = reader.pages[page_number]\n",
    "        rotation_angle = determine_rotation_angle(current_page)\n",
    "        angles.append(rotation_angle)\n",
    "    return angles\n",
    "\n",
    "def determine_rotation_angle(page: 'PdfReader.PageObject') -> int:\n",
    "    \"\"\"\n",
    "    Determine the rotation angle needed to make the page upright.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    int:  The rotation angle in degrees (e.g. 0, 90, 210).\n",
    "          The rotation angle is  normalized to be in the range [0, 359].\n",
    "          0 means the page is already upright, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    # Extract the text content of the page\n",
    "    text = extract_text_from_page(page)\n",
    "    if not text.strip():\n",
    "        return 0  # If no text is found, assume the page is upright\n",
    "    \n",
    "    # Use Tesseract to determine the orientation\n",
    "    orientation = pytesseract.image_to_osd(text, config='--psm 0')['rotate']\n",
    "    \n",
    "    # Normalize the orientation to be in the range [0, 359]\n",
    "    rotation_angle = (360 - orientation) % 360\n",
    "    return rotation_angle\n",
    "\n",
    "def extract_text_from_page(page: 'PdfReader.PageObject') -> str:\n",
    "    \"\"\"\n",
    "    Extract text from a PDF page using OCR.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    str: The extracted text content.\n",
    "    \"\"\"\n",
    "    # Convert the PDF page to an image\n",
    "    page_image = convert_pdf_page_to_image(page)\n",
    "    \n",
    "    # Use Tesseract to extract text from the image\n",
    "    text = pytesseract.image_to_string(page_image)\n",
    "    return text\n",
    "\n",
    "def convert_pdf_page_to_image(page: 'PdfReader.PageObject') -> 'Image':\n",
    "    \"\"\"\n",
    "    Convert a PDF page to an image.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    Image: The converted image.\n",
    "    \"\"\"\n",
    "    pdf_writer = PdfWriter()\n",
    "    pdf_writer.add_page(page)\n",
    "    \n",
    "    # Save the single-page PDF to a byte buffer\n",
    "    pdf_bytes = io.BytesIO()\n",
    "    pdf_writer.write(pdf_bytes)\n",
    "    pdf_bytes.seek(0)\n",
    "    \n",
    "    # Convert the single-page PDF to an image using PIL\n",
    "    image = Image.open(pdf_bytes)\n",
    "    return image\n",
    "\n",
    "# Usage\n",
    "input_pdf = \"grouped_documents.pdf\"\n",
    "rotation_angles = rotate_all_pages_upright(input_pdf)\n",
    "print(f\"Rotation angles for each page: {rotation_angles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b8d9801-cabf-4121-97b6-f174672f7b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arues\\AppData\\Local\\Temp\\tmp7x32dra1.pdf\n"
     ]
    },
    {
     "ename": "PDFPageCountError",
     "evalue": "Unable to get page count.\nI/O Error: Couldn't open file 'C:\\Users\\arues\\AppData\\Local\\Temp\\tmp7x32dra1.pdf': No error.\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\hiringstudy01\\Lib\\site-packages\\pdf2image\\pdf2image.py:602\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[1;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPages\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m d:\n\u001b[1;32m--> 602\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "\u001b[1;31mValueError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPDFPageCountError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[0;32m     78\u001b[0m input_pdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrouped_documents.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 79\u001b[0m rotation_angles \u001b[38;5;241m=\u001b[39m rotate_all_pages_upright(input_pdf)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRotation angles for each page: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrotation_angles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 23\u001b[0m, in \u001b[0;36mrotate_all_pages_upright\u001b[1;34m(input_pdf)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_number \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(reader\u001b[38;5;241m.\u001b[39mpages)):\n\u001b[0;32m     22\u001b[0m     current_page \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mpages[page_number]\n\u001b[1;32m---> 23\u001b[0m     rotation_angle \u001b[38;5;241m=\u001b[39m determine_rotation_angle(current_page)\n\u001b[0;32m     24\u001b[0m     angles\u001b[38;5;241m.\u001b[39mappend(rotation_angle)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m angles\n",
      "Cell \u001b[1;32mIn[11], line 40\u001b[0m, in \u001b[0;36mdetermine_rotation_angle\u001b[1;34m(page)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03mDetermine the rotation angle needed to make the page upright.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m      0 means the page is already upright, 90 means 90 degrees clockwise, etc.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Extract the image of the page\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m page_image \u001b[38;5;241m=\u001b[39m convert_pdf_page_to_image(page)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Use Tesseract to determine the orientation\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[11], line 73\u001b[0m, in \u001b[0;36mconvert_pdf_page_to_image\u001b[1;34m(page)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(temp_pdf\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m#temp_pdf.flush()\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# Convert the single-page PDF to an image using pdf2image\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     images \u001b[38;5;241m=\u001b[39m convert_from_path(temp_pdf\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m images[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\hiringstudy01\\Lib\\site-packages\\pdf2image\\pdf2image.py:127\u001b[0m, in \u001b[0;36mconvert_from_path\u001b[1;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, ownerpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(poppler_path, PurePath):\n\u001b[0;32m    125\u001b[0m     poppler_path \u001b[38;5;241m=\u001b[39m poppler_path\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[1;32m--> 127\u001b[0m page_count \u001b[38;5;241m=\u001b[39m pdfinfo_from_path(\n\u001b[0;32m    128\u001b[0m     pdf_path, userpw, ownerpw, poppler_path\u001b[38;5;241m=\u001b[39mpoppler_path\n\u001b[0;32m    129\u001b[0m )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# We start by getting the output format, the buffer processing function and if we need pdftocairo\u001b[39;00m\n\u001b[0;32m    132\u001b[0m parsed_fmt, final_extension, parse_buffer_func, use_pdfcairo_format \u001b[38;5;241m=\u001b[39m _parse_format(\n\u001b[0;32m    133\u001b[0m     fmt, grayscale\n\u001b[0;32m    134\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\hiringstudy01\\Lib\\site-packages\\pdf2image\\pdf2image.py:611\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[1;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFInfoNotInstalledError(\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count. Is poppler installed and in PATH?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    609\u001b[0m     )\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFPageCountError(\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m     )\n",
      "\u001b[1;31mPDFPageCountError\u001b[0m: Unable to get page count.\nI/O Error: Couldn't open file 'C:\\Users\\arues\\AppData\\Local\\Temp\\tmp7x32dra1.pdf': No error.\r\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from PyPDF2 import PdfReader\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import tempfile\n",
    "\n",
    "def rotate_all_pages_upright(input_pdf: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Analyze all pages in the input PDF and determine the rotation angle needed for each page.\n",
    "\n",
    "    Args:\n",
    "    input_pdf (str): The file path of the input PDF.\n",
    "\n",
    "    Returns:\n",
    "    List[int]: A list of rotation angles (in degrees) for each page. \n",
    "               The angles are normalized to be in the range [0, 359].\n",
    "               0 means no rotation needed, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf)\n",
    "    angles = []\n",
    "    for page_number in range(len(reader.pages)):\n",
    "        current_page = reader.pages[page_number]\n",
    "        rotation_angle = determine_rotation_angle(current_page)\n",
    "        angles.append(rotation_angle)\n",
    "    return angles\n",
    "\n",
    "def determine_rotation_angle(page: 'PdfReader.PageObject') -> int:\n",
    "    \"\"\"\n",
    "    Determine the rotation angle needed to make the page upright.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    int:  The rotation angle in degrees (e.g. 0, 90, 210).\n",
    "          The rotation angle is  normalized to be in the range [0, 359].\n",
    "          0 means the page is already upright, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    # Extract the image of the page\n",
    "    page_image = convert_pdf_page_to_image(page)\n",
    "    \n",
    "    # Use Tesseract to determine the orientation\n",
    "    try:\n",
    "        osd = pytesseract.image_to_osd(page_image)\n",
    "        rotation_angle = int(osd.split(\"Rotate:\")[1].split(\"\\n\")[0].strip())\n",
    "    except:\n",
    "        rotation_angle = 0\n",
    "    \n",
    "    # Normalize the orientation to be in the range [0, 359]\n",
    "    rotation_angle = (360 - rotation_angle) % 360\n",
    "    return rotation_angle\n",
    "\n",
    "def convert_pdf_page_to_image(page: 'PdfReader.PageObject') -> 'Image':\n",
    "    \"\"\"\n",
    "    Convert a PDF page to an image.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    Image: The converted image.\n",
    "    \"\"\"\n",
    "    pdf_writer = PdfWriter()\n",
    "    pdf_writer.add_page(page)\n",
    "    \n",
    "    # Save the single-page PDF to a temporary file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".pdf\") as temp_pdf:\n",
    "        pdf_writer.write(temp_pdf)\n",
    "        temp_pdf.flush()\n",
    "        \n",
    "        # Convert the single-page PDF to an image using pdf2image\n",
    "        images = convert_from_path(temp_pdf.name)\n",
    "    \n",
    "    return images[0]  # There should be only one page, hence one image\n",
    "\n",
    "# Usage\n",
    "input_pdf = \"grouped_documents.pdf\"\n",
    "rotation_angles = rotate_all_pages_upright(input_pdf)\n",
    "print(f\"Rotation angles for each page: {rotation_angles}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7665b773-5420-4d75-af8a-86994cc59d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation angles for each page: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from pdf2image import convert_from_path\n",
    "from IPython.display import display\n",
    "import pytesseract\n",
    "import tempfile\n",
    "\n",
    "def rotate_all_pages_upright(input_pdf: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Analyze all pages in the input PDF and determine the rotation angle needed for each page.\n",
    "\n",
    "    Args:\n",
    "    input_pdf (str): The file path of the input PDF.\n",
    "\n",
    "    Returns:\n",
    "    List[int]: A list of rotation angles (in degrees) for each page. \n",
    "               The angles are normalized to be in the range [0, 359].\n",
    "               0 means no rotation needed, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf)\n",
    "    angles = []\n",
    "    for page_number in range(len(reader.pages)):\n",
    "        current_page = reader.pages[page_number]\n",
    "        rotation_angle = determine_rotation_angle(current_page)\n",
    "        angles.append(rotation_angle)\n",
    "    return angles\n",
    "\n",
    "def determine_rotation_angle(page: 'PdfReader.PageObject') -> int:\n",
    "    \"\"\"\n",
    "    Determine the rotation angle needed to make the page upright.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    int:  The rotation angle in degrees (e.g. 0, 90, 210).\n",
    "          The rotation angle is  normalized to be in the range [0, 359].\n",
    "          0 means the page is already upright, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    # Extract the image of the page\n",
    "    page_image = convert_pdf_page_to_image(page)\n",
    "    \n",
    "    #display(page_image)\n",
    "    \n",
    "    # Use Tesseract to determine the orientation\n",
    "    try:\n",
    "        osd = pytesseract.image_to_osd(page_image)\n",
    "        print(osd)\n",
    "        rotation_angle = int(osd.split(\"Rotate:\")[1].split(\"\\n\")[0].strip())\n",
    "    except:\n",
    "        rotation_angle = 0\n",
    "    \n",
    "    # Normalize the orientation to be in the range [0, 359]\n",
    "    rotation_angle = (360 - rotation_angle) % 360\n",
    "    return rotation_angle\n",
    "\n",
    "def convert_pdf_page_to_image(page: 'PdfReader.PageObject') -> 'Image':\n",
    "    \"\"\"\n",
    "    Convert a PDF page to an image.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    Image: The converted image.\n",
    "    \"\"\"\n",
    "    pdf_writer = PdfWriter()\n",
    "    pdf_writer.add_page(page)\n",
    "    \n",
    "    # Save the single-page PDF to a temporary file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".pdf\", delete=False) as temp_pdf:\n",
    "        pdf_writer.write(temp_pdf)\n",
    "        temp_pdf_path = temp_pdf.name\n",
    "    \n",
    "    # Convert the single-page PDF to an image using pdf2image\n",
    "    images = convert_from_path(temp_pdf_path)\n",
    "    \n",
    "    # Clean up the temporary file\n",
    "    import os\n",
    "    os.remove(temp_pdf_path)\n",
    "    \n",
    "    return images[0]  # There should be only one page, hence one image\n",
    "\n",
    "# Usage\n",
    "input_pdf = \"grouped_documents.pdf\"\n",
    "rotation_angles = rotate_all_pages_upright(input_pdf)\n",
    "print(f\"Rotation angles for each page: {rotation_angles}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fef6fd-90d5-4b09-8147-d4dd909d1b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Error in OSD: [WinError 5] Access is denied\n",
      "Rotation angles for each page: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import tempfile\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'\"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"'\n",
    "\n",
    "def rotate_all_pages_upright(input_pdf: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Analyze all pages in the input PDF and determine the rotation angle needed for each page.\n",
    "\n",
    "    Args:\n",
    "    input_pdf (str): The file path of the input PDF.\n",
    "\n",
    "    Returns:\n",
    "    List[int]: A list of rotation angles (in degrees) for each page. \n",
    "               The angles are normalized to be in the range [0, 359].\n",
    "               0 means no rotation needed, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf)\n",
    "    angles = []\n",
    "    for page_number in range(len(reader.pages)):\n",
    "        current_page = reader.pages[page_number]\n",
    "        rotation_angle = determine_rotation_angle(current_page)\n",
    "        angles.append(rotation_angle)\n",
    "    return angles\n",
    "\n",
    "def determine_rotation_angle(page: 'PdfReader.PageObject') -> int:\n",
    "    \"\"\"\n",
    "    Determine the rotation angle needed to make the page upright.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    int:  The rotation angle in degrees (e.g. 0, 90, 210).\n",
    "          The rotation angle is  normalized to be in the range [0, 359].\n",
    "          0 means the page is already upright, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    # Extract the image of the page\n",
    "    page_image = convert_pdf_page_to_image(page)\n",
    "    \n",
    "    # Use Tesseract to determine the orientation\n",
    "    try:\n",
    "        osd = pytesseract.image_to_osd(page_image)\n",
    "        print(f\"Tesseract OSD output: {osd}\")  # Debug print\n",
    "        rotation_angle = int(osd.split(\"Rotate:\")[1].split(\"\\n\")[0].strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OSD: {e}\")  # Debug print\n",
    "        rotation_angle = 0\n",
    "    \n",
    "    # Normalize the orientation to be in the range [0, 359]\n",
    "    rotation_angle = (360 - rotation_angle) % 360\n",
    "    return rotation_angle\n",
    "\n",
    "def convert_pdf_page_to_image(page: 'PdfReader.PageObject') -> 'Image':\n",
    "    \"\"\"\n",
    "    Convert a PDF page to an image.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    Image: The converted image.\n",
    "    \"\"\"\n",
    "    pdf_writer = PdfWriter()\n",
    "    pdf_writer.add_page(page)\n",
    "    \n",
    "    # Save the single-page PDF to a temporary file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".pdf\", delete=False) as temp_pdf:\n",
    "        pdf_writer.write(temp_pdf)\n",
    "        temp_pdf_path = temp_pdf.name\n",
    "    \n",
    "    # Convert the single-page PDF to an image using pdf2image\n",
    "    images = convert_from_path(temp_pdf_path)\n",
    "    \n",
    "    # Clean up the temporary file\n",
    "    os.remove(temp_pdf_path)\n",
    "    \n",
    "    return images[0]  # There should be only one page, hence one image\n",
    "\n",
    "# Usage\n",
    "output_pdf = \"grouped_documents.pdf\"\n",
    "#create_rotated_text_pdf(output_pdf)\n",
    "rotation_angles = rotate_all_pages_upright(output_pdf)\n",
    "print(f\"Rotation angles for each page: {rotation_angles}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a05d469-df39-4f20-8c5c-9fc9750a8de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in OSD: (1, 'Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 306 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 294 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 196 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 125 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 341 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 323 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 356 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 319 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 272 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 242 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 365 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 364 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 366 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 175 Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 222 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Rotation angles for each page: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import tempfile\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Specify the Tesseract executable path\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update this path if necessary\n",
    "\n",
    "def rotate_all_pages_upright(input_pdf: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Analyze all pages in the input PDF and determine the rotation angle needed for each page.\n",
    "\n",
    "    Args:\n",
    "    input_pdf (str): The file path of the input PDF.\n",
    "\n",
    "    Returns:\n",
    "    List[int]: A list of rotation angles (in degrees) for each page. \n",
    "               The angles are normalized to be in the range [0, 359].\n",
    "               0 means no rotation needed, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf)\n",
    "    angles = []\n",
    "    for page_number in range(len(reader.pages)):\n",
    "        current_page = reader.pages[page_number]\n",
    "        rotation_angle = determine_rotation_angle(current_page)\n",
    "        angles.append(rotation_angle)\n",
    "    return angles\n",
    "\n",
    "def determine_rotation_angle(page: 'PdfReader.PageObject') -> int:\n",
    "    \"\"\"\n",
    "    Determine the rotation angle needed to make the page upright.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    int:  The rotation angle in degrees (e.g. 0, 90, 210).\n",
    "          The rotation angle is  normalized to be in the range [0, 359].\n",
    "          0 means the page is already upright, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    # Extract the image of the page\n",
    "    page_image = convert_pdf_page_to_image(page)\n",
    "    \n",
    "    # Use Tesseract to determine the orientation\n",
    "    try:\n",
    "        osd = pytesseract.image_to_osd(page_image)\n",
    "        print(f\"Tesseract OSD output: {osd}\")  # Debug print\n",
    "        rotation_angle = int(osd.split(\"Rotate:\")[1].split(\"\\n\")[0].strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OSD: {e}\")  # Debug print\n",
    "        rotation_angle = 0\n",
    "    \n",
    "    # Normalize the orientation to be in the range [0, 359]\n",
    "    rotation_angle = (360 - rotation_angle) % 360\n",
    "    return rotation_angle\n",
    "\n",
    "def convert_pdf_page_to_image(page: 'PdfReader.PageObject') -> 'Image':\n",
    "    \"\"\"\n",
    "    Convert a PDF page to an image.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    Image: The converted image.\n",
    "    \"\"\"\n",
    "    pdf_writer = PdfWriter()\n",
    "    pdf_writer.add_page(page)\n",
    "    \n",
    "    # Save the single-page PDF to a temporary file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".pdf\", delete=False) as temp_pdf:\n",
    "        pdf_writer.write(temp_pdf)\n",
    "        temp_pdf_path = temp_pdf.name\n",
    "    \n",
    "    # Convert the single-page PDF to an image using pdf2image\n",
    "    images = convert_from_path(temp_pdf_path)\n",
    "    \n",
    "    # Clean up the temporary file\n",
    "    os.remove(temp_pdf_path)\n",
    "    \n",
    "    return images[0]  # There should be only one page, hence one image\n",
    "\n",
    "# Usage\n",
    "output_pdf = \"grouped_documents.pdf\"\n",
    "#create_rotated_text_pdf(output_pdf)\n",
    "rotation_angles = rotate_all_pages_upright(output_pdf)\n",
    "print(f\"Rotation angles for each page: {rotation_angles}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33a4461-cbc3-4f4d-9830-b408b385d4bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in OSD: (1, 'Estimating resolution as 454 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Tesseract OSD output: Page number: 0\n",
      "Orientation in degrees: 0\n",
      "Rotate: 0\n",
      "Orientation confidence: 1.11\n",
      "Script: Latin\n",
      "Script confidence: 3.33\n",
      "\n",
      "Tesseract OSD output: Page number: 0\n",
      "Orientation in degrees: 0\n",
      "Rotate: 0\n",
      "Orientation confidence: 0.53\n",
      "Script: Latin\n",
      "Script confidence: 6.67\n",
      "\n",
      "Error in OSD: (1, 'Estimating resolution as 269 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 288 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 252 Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Tesseract OSD output: Page number: 0\n",
      "Orientation in degrees: 90\n",
      "Rotate: 270\n",
      "Orientation confidence: 0.75\n",
      "Script: Latin\n",
      "Script confidence: 16.67\n",
      "\n",
      "Tesseract OSD output: Page number: 0\n",
      "Orientation in degrees: 0\n",
      "Rotate: 0\n",
      "Orientation confidence: 0.18\n",
      "Script: Latin\n",
      "Script confidence: 6.67\n",
      "\n",
      "Tesseract OSD output: Page number: 0\n",
      "Orientation in degrees: 0\n",
      "Rotate: 0\n",
      "Orientation confidence: 0.60\n",
      "Script: Latin\n",
      "Script confidence: 6.67\n",
      "\n",
      "Error in OSD: (1, 'Estimating resolution as 545 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 475 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 438 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 438 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 559 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 550 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 627 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 308 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Error in OSD: (1, 'Estimating resolution as 325 Too few characters. Skipping this page Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')\n",
      "Rotation angles for each page: [0, 0, 0, 0, 0, 0, 90, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import tempfile\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Specify the Tesseract executable path\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update this path if necessary\n",
    "\n",
    "def rotate_all_pages_upright(input_pdf: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Analyze all pages in the input PDF and determine the rotation angle needed for each page.\n",
    "\n",
    "    Args:\n",
    "    input_pdf (str): The file path of the input PDF.\n",
    "\n",
    "    Returns:\n",
    "    List[int]: A list of rotation angles (in degrees) for each page. \n",
    "               The angles are normalized to be in the range [0, 359].\n",
    "               0 means no rotation needed, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf)\n",
    "    angles = []\n",
    "    for page_number in range(len(reader.pages)):\n",
    "        current_page = reader.pages[page_number]\n",
    "        rotation_angle = determine_rotation_angle(current_page)\n",
    "        angles.append(rotation_angle)\n",
    "    return angles\n",
    "\n",
    "def determine_rotation_angle(page: 'PdfReader.PageObject') -> int:\n",
    "    \"\"\"\n",
    "    Determine the rotation angle needed to make the page upright.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    int: The rotation angle in degrees (e.g. 0, 90, 210).\n",
    "         The rotation angle is normalized to be in the range [0, 359].\n",
    "         0 means the page is already upright, 90 means 90 degrees clockwise, etc.\n",
    "    \"\"\"\n",
    "    # Extract the image of the page\n",
    "    page_image = convert_pdf_page_to_image(page)\n",
    "    \n",
    "    # Use Tesseract to determine the orientation\n",
    "    try:\n",
    "        osd = pytesseract.image_to_osd(page_image)\n",
    "        print(f\"Tesseract OSD output: {osd}\")  # Debug print\n",
    "        rotation_angle = int(osd.split(\"Rotate:\")[1].split(\"\\n\")[0].strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OSD: {e}\")  # Debug print\n",
    "        rotation_angle = 0\n",
    "    \n",
    "    # Normalize the orientation to be in the range [0, 359]\n",
    "    rotation_angle = (360 - rotation_angle) % 360\n",
    "    return rotation_angle\n",
    "\n",
    "def convert_pdf_page_to_image(page: 'PdfReader.PageObject') -> 'Image':\n",
    "    \"\"\"\n",
    "    Convert a PDF page to an image.\n",
    "\n",
    "    Args:\n",
    "    page (PdfReader.PageObject): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "    Image: The converted image.\n",
    "    \"\"\"\n",
    "    pdf_writer = PdfWriter()\n",
    "    pdf_writer.add_page(page)\n",
    "    \n",
    "    # Save the single-page PDF to a temporary file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".pdf\", delete=False) as temp_pdf:\n",
    "        pdf_writer.write(temp_pdf)\n",
    "        temp_pdf_path = temp_pdf.name\n",
    "    \n",
    "    # Convert the single-page PDF to an image using pdf2image with higher resolution\n",
    "    images = convert_from_path(temp_pdf_path, dpi=300)\n",
    "    \n",
    "    # Clean up the temporary file\n",
    "    os.remove(temp_pdf_path)\n",
    "    \n",
    "    return images[0]  # There should be only one page, hence one image\n",
    "\n",
    "# Usage\n",
    "output_pdf = \"grouped_documents.pdf\"\n",
    "rotation_angles = rotate_all_pages_upright(output_pdf)\n",
    "print(f\"Rotation angles for each page: {rotation_angles}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a819a0c5-226e-445b-8d0f-ea34bb26de41",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for AngleRegressionModel:\n\tMissing key(s) in state_dict: \"model.fc.weight\", \"model.fc.bias\". \n\tUnexpected key(s) in state_dict: \"model.layer1.2.conv1.weight\", \"model.layer1.2.bn1.weight\", \"model.layer1.2.bn1.bias\", \"model.layer1.2.bn1.running_mean\", \"model.layer1.2.bn1.running_var\", \"model.layer1.2.bn1.num_batches_tracked\", \"model.layer1.2.conv2.weight\", \"model.layer1.2.bn2.weight\", \"model.layer1.2.bn2.bias\", \"model.layer1.2.bn2.running_mean\", \"model.layer1.2.bn2.running_var\", \"model.layer1.2.bn2.num_batches_tracked\", \"model.layer1.2.conv3.weight\", \"model.layer1.2.bn3.weight\", \"model.layer1.2.bn3.bias\", \"model.layer1.2.bn3.running_mean\", \"model.layer1.2.bn3.running_var\", \"model.layer1.2.bn3.num_batches_tracked\", \"model.layer1.0.conv3.weight\", \"model.layer1.0.bn3.weight\", \"model.layer1.0.bn3.bias\", \"model.layer1.0.bn3.running_mean\", \"model.layer1.0.bn3.running_var\", \"model.layer1.0.bn3.num_batches_tracked\", \"model.layer1.0.downsample.0.weight\", \"model.layer1.0.downsample.1.weight\", \"model.layer1.0.downsample.1.bias\", \"model.layer1.0.downsample.1.running_mean\", \"model.layer1.0.downsample.1.running_var\", \"model.layer1.0.downsample.1.num_batches_tracked\", \"model.layer1.1.conv3.weight\", \"model.layer1.1.bn3.weight\", \"model.layer1.1.bn3.bias\", \"model.layer1.1.bn3.running_mean\", \"model.layer1.1.bn3.running_var\", \"model.layer1.1.bn3.num_batches_tracked\", \"model.layer2.2.conv1.weight\", \"model.layer2.2.bn1.weight\", \"model.layer2.2.bn1.bias\", \"model.layer2.2.bn1.running_mean\", \"model.layer2.2.bn1.running_var\", \"model.layer2.2.bn1.num_batches_tracked\", \"model.layer2.2.conv2.weight\", \"model.layer2.2.bn2.weight\", \"model.layer2.2.bn2.bias\", \"model.layer2.2.bn2.running_mean\", \"model.layer2.2.bn2.running_var\", \"model.layer2.2.bn2.num_batches_tracked\", \"model.layer2.2.conv3.weight\", \"model.layer2.2.bn3.weight\", \"model.layer2.2.bn3.bias\", \"model.layer2.2.bn3.running_mean\", \"model.layer2.2.bn3.running_var\", \"model.layer2.2.bn3.num_batches_tracked\", \"model.layer2.3.conv1.weight\", \"model.layer2.3.bn1.weight\", \"model.layer2.3.bn1.bias\", \"model.layer2.3.bn1.running_mean\", \"model.layer2.3.bn1.running_var\", \"model.layer2.3.bn1.num_batches_tracked\", \"model.layer2.3.conv2.weight\", \"model.layer2.3.bn2.weight\", \"model.layer2.3.bn2.bias\", \"model.layer2.3.bn2.running_mean\", \"model.layer2.3.bn2.running_var\", \"model.layer2.3.bn2.num_batches_tracked\", \"model.layer2.3.conv3.weight\", \"model.layer2.3.bn3.weight\", \"model.layer2.3.bn3.bias\", \"model.layer2.3.bn3.running_mean\", \"model.layer2.3.bn3.running_var\", \"model.layer2.3.bn3.num_batches_tracked\", \"model.layer2.0.conv3.weight\", \"model.layer2.0.bn3.weight\", \"model.layer2.0.bn3.bias\", \"model.layer2.0.bn3.running_mean\", \"model.layer2.0.bn3.running_var\", \"model.layer2.0.bn3.num_batches_tracked\", \"model.layer2.1.conv3.weight\", \"model.layer2.1.bn3.weight\", \"model.layer2.1.bn3.bias\", \"model.layer2.1.bn3.running_mean\", \"model.layer2.1.bn3.running_var\", \"model.layer2.1.bn3.num_batches_tracked\", \"model.layer3.2.conv1.weight\", \"model.layer3.2.bn1.weight\", \"model.layer3.2.bn1.bias\", \"model.layer3.2.bn1.running_mean\", \"model.layer3.2.bn1.running_var\", \"model.layer3.2.bn1.num_batches_tracked\", \"model.layer3.2.conv2.weight\", \"model.layer3.2.bn2.weight\", \"model.layer3.2.bn2.bias\", \"model.layer3.2.bn2.running_mean\", \"model.layer3.2.bn2.running_var\", \"model.layer3.2.bn2.num_batches_tracked\", \"model.layer3.2.conv3.weight\", \"model.layer3.2.bn3.weight\", \"model.layer3.2.bn3.bias\", \"model.layer3.2.bn3.running_mean\", \"model.layer3.2.bn3.running_var\", \"model.layer3.2.bn3.num_batches_tracked\", \"model.layer3.3.conv1.weight\", \"model.layer3.3.bn1.weight\", \"model.layer3.3.bn1.bias\", \"model.layer3.3.bn1.running_mean\", \"model.layer3.3.bn1.running_var\", \"model.layer3.3.bn1.num_batches_tracked\", \"model.layer3.3.conv2.weight\", \"model.layer3.3.bn2.weight\", \"model.layer3.3.bn2.bias\", \"model.layer3.3.bn2.running_mean\", \"model.layer3.3.bn2.running_var\", \"model.layer3.3.bn2.num_batches_tracked\", \"model.layer3.3.conv3.weight\", \"model.layer3.3.bn3.weight\", \"model.layer3.3.bn3.bias\", \"model.layer3.3.bn3.running_mean\", \"model.layer3.3.bn3.running_var\", \"model.layer3.3.bn3.num_batches_tracked\", \"model.layer3.4.conv1.weight\", \"model.layer3.4.bn1.weight\", \"model.layer3.4.bn1.bias\", \"model.layer3.4.bn1.running_mean\", \"model.layer3.4.bn1.running_var\", \"model.layer3.4.bn1.num_batches_tracked\", \"model.layer3.4.conv2.weight\", \"model.layer3.4.bn2.weight\", \"model.layer3.4.bn2.bias\", \"model.layer3.4.bn2.running_mean\", \"model.layer3.4.bn2.running_var\", \"model.layer3.4.bn2.num_batches_tracked\", \"model.layer3.4.conv3.weight\", \"model.layer3.4.bn3.weight\", \"model.layer3.4.bn3.bias\", \"model.layer3.4.bn3.running_mean\", \"model.layer3.4.bn3.running_var\", \"model.layer3.4.bn3.num_batches_tracked\", \"model.layer3.5.conv1.weight\", \"model.layer3.5.bn1.weight\", \"model.layer3.5.bn1.bias\", \"model.layer3.5.bn1.running_mean\", \"model.layer3.5.bn1.running_var\", \"model.layer3.5.bn1.num_batches_tracked\", \"model.layer3.5.conv2.weight\", \"model.layer3.5.bn2.weight\", \"model.layer3.5.bn2.bias\", \"model.layer3.5.bn2.running_mean\", \"model.layer3.5.bn2.running_var\", \"model.layer3.5.bn2.num_batches_tracked\", \"model.layer3.5.conv3.weight\", \"model.layer3.5.bn3.weight\", \"model.layer3.5.bn3.bias\", \"model.layer3.5.bn3.running_mean\", \"model.layer3.5.bn3.running_var\", \"model.layer3.5.bn3.num_batches_tracked\", \"model.layer3.0.conv3.weight\", \"model.layer3.0.bn3.weight\", \"model.layer3.0.bn3.bias\", \"model.layer3.0.bn3.running_mean\", \"model.layer3.0.bn3.running_var\", \"model.layer3.0.bn3.num_batches_tracked\", \"model.layer3.1.conv3.weight\", \"model.layer3.1.bn3.weight\", \"model.layer3.1.bn3.bias\", \"model.layer3.1.bn3.running_mean\", \"model.layer3.1.bn3.running_var\", \"model.layer3.1.bn3.num_batches_tracked\", \"model.layer4.2.conv1.weight\", \"model.layer4.2.bn1.weight\", \"model.layer4.2.bn1.bias\", \"model.layer4.2.bn1.running_mean\", \"model.layer4.2.bn1.running_var\", \"model.layer4.2.bn1.num_batches_tracked\", \"model.layer4.2.conv2.weight\", \"model.layer4.2.bn2.weight\", \"model.layer4.2.bn2.bias\", \"model.layer4.2.bn2.running_mean\", \"model.layer4.2.bn2.running_var\", \"model.layer4.2.bn2.num_batches_tracked\", \"model.layer4.2.conv3.weight\", \"model.layer4.2.bn3.weight\", \"model.layer4.2.bn3.bias\", \"model.layer4.2.bn3.running_mean\", \"model.layer4.2.bn3.running_var\", \"model.layer4.2.bn3.num_batches_tracked\", \"model.layer4.0.conv3.weight\", \"model.layer4.0.bn3.weight\", \"model.layer4.0.bn3.bias\", \"model.layer4.0.bn3.running_mean\", \"model.layer4.0.bn3.running_var\", \"model.layer4.0.bn3.num_batches_tracked\", \"model.layer4.1.conv3.weight\", \"model.layer4.1.bn3.weight\", \"model.layer4.1.bn3.bias\", \"model.layer4.1.bn3.running_mean\", \"model.layer4.1.bn3.running_var\", \"model.layer4.1.bn3.num_batches_tracked\", \"model.fc.1.weight\", \"model.fc.1.bias\". \n\tsize mismatch for model.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for model.layer2.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1, 1]).\n\tsize mismatch for model.layer2.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for model.layer2.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for model.layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for model.layer2.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for model.layer2.1.conv1.weight: copying a param with shape torch.Size([128, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for model.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for model.layer3.0.downsample.0.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 1, 1]).\n\tsize mismatch for model.layer3.0.downsample.1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.layer3.0.downsample.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.layer3.0.downsample.1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.layer3.1.conv1.weight: copying a param with shape torch.Size([256, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for model.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).\n\tsize mismatch for model.layer4.0.downsample.0.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for model.layer4.0.downsample.1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.layer4.0.downsample.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.layer4.0.downsample.1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.layer4.1.conv1.weight: copying a param with shape torch.Size([512, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m output_pdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrouped_documents.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mangle_regression_model_2.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Path to your pre-trained model\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m rotation_angles \u001b[38;5;241m=\u001b[39m rotate_all_pages_upright(output_pdf, model_path)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRotation angles for each page: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrotation_angles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 65\u001b[0m, in \u001b[0;36mrotate_all_pages_upright\u001b[1;34m(input_pdf, model_path)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrotate_all_pages_upright\u001b[39m(input_pdf: \u001b[38;5;28mstr\u001b[39m, model_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m---> 65\u001b[0m     model \u001b[38;5;241m=\u001b[39m load_angle_regression_model(model_path)\n\u001b[0;32m     66\u001b[0m     reader \u001b[38;5;241m=\u001b[39m PdfReader(input_pdf)\n\u001b[0;32m     67\u001b[0m     angles \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m, in \u001b[0;36mload_angle_regression_model\u001b[1;34m(model_path)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_angle_regression_model\u001b[39m(model_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     24\u001b[0m     model \u001b[38;5;241m=\u001b[39m AngleRegressionModel()\n\u001b[1;32m---> 25\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m     26\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\hiringstudy01\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AngleRegressionModel:\n\tMissing key(s) in state_dict: \"model.fc.weight\", \"model.fc.bias\". \n\tUnexpected key(s) in state_dict: \"model.layer1.2.conv1.weight\", \"model.layer1.2.bn1.weight\", \"model.layer1.2.bn1.bias\", \"model.layer1.2.bn1.running_mean\", \"model.layer1.2.bn1.running_var\", \"model.layer1.2.bn1.num_batches_tracked\", \"model.layer1.2.conv2.weight\", \"model.layer1.2.bn2.weight\", \"model.layer1.2.bn2.bias\", \"model.layer1.2.bn2.running_mean\", \"model.layer1.2.bn2.running_var\", \"model.layer1.2.bn2.num_batches_tracked\", \"model.layer1.2.conv3.weight\", \"model.layer1.2.bn3.weight\", \"model.layer1.2.bn3.bias\", \"model.layer1.2.bn3.running_mean\", \"model.layer1.2.bn3.running_var\", \"model.layer1.2.bn3.num_batches_tracked\", \"model.layer1.0.conv3.weight\", \"model.layer1.0.bn3.weight\", \"model.layer1.0.bn3.bias\", \"model.layer1.0.bn3.running_mean\", \"model.layer1.0.bn3.running_var\", \"model.layer1.0.bn3.num_batches_tracked\", \"model.layer1.0.downsample.0.weight\", \"model.layer1.0.downsample.1.weight\", \"model.layer1.0.downsample.1.bias\", \"model.layer1.0.downsample.1.running_mean\", \"model.layer1.0.downsample.1.running_var\", \"model.layer1.0.downsample.1.num_batches_tracked\", \"model.layer1.1.conv3.weight\", \"model.layer1.1.bn3.weight\", \"model.layer1.1.bn3.bias\", \"model.layer1.1.bn3.running_mean\", \"model.layer1.1.bn3.running_var\", \"model.layer1.1.bn3.num_batches_tracked\", \"model.layer2.2.conv1.weight\", \"model.layer2.2.bn1.weight\", \"model.layer2.2.bn1.bias\", \"model.layer2.2.bn1.running_mean\", \"model.layer2.2.bn1.running_var\", \"model.layer2.2.bn1.num_batches_tracked\", \"model.layer2.2.conv2.weight\", \"model.layer2.2.bn2.weight\", \"model.layer2.2.bn2.bias\", \"model.layer2.2.bn2.running_mean\", \"model.layer2.2.bn2.running_var\", \"model.layer2.2.bn2.num_batches_tracked\", \"model.layer2.2.conv3.weight\", \"model.layer2.2.bn3.weight\", \"model.layer2.2.bn3.bias\", \"model.layer2.2.bn3.running_mean\", \"model.layer2.2.bn3.running_var\", \"model.layer2.2.bn3.num_batches_tracked\", \"model.layer2.3.conv1.weight\", \"model.layer2.3.bn1.weight\", \"model.layer2.3.bn1.bias\", \"model.layer2.3.bn1.running_mean\", \"model.layer2.3.bn1.running_var\", \"model.layer2.3.bn1.num_batches_tracked\", \"model.layer2.3.conv2.weight\", \"model.layer2.3.bn2.weight\", \"model.layer2.3.bn2.bias\", \"model.layer2.3.bn2.running_mean\", \"model.layer2.3.bn2.running_var\", \"model.layer2.3.bn2.num_batches_tracked\", \"model.layer2.3.conv3.weight\", \"model.layer2.3.bn3.weight\", \"model.layer2.3.bn3.bias\", \"model.layer2.3.bn3.running_mean\", \"model.layer2.3.bn3.running_var\", \"model.layer2.3.bn3.num_batches_tracked\", \"model.layer2.0.conv3.weight\", \"model.layer2.0.bn3.weight\", \"model.layer2.0.bn3.bias\", \"model.layer2.0.bn3.running_mean\", \"model.layer2.0.bn3.running_var\", \"model.layer2.0.bn3.num_batches_tracked\", \"model.layer2.1.conv3.weight\", \"model.layer2.1.bn3.weight\", \"model.layer2.1.bn3.bias\", \"model.layer2.1.bn3.running_mean\", \"model.layer2.1.bn3.running_var\", \"model.layer2.1.bn3.num_batches_tracked\", \"model.layer3.2.conv1.weight\", \"model.layer3.2.bn1.weight\", \"model.layer3.2.bn1.bias\", \"model.layer3.2.bn1.running_mean\", \"model.layer3.2.bn1.running_var\", \"model.layer3.2.bn1.num_batches_tracked\", \"model.layer3.2.conv2.weight\", \"model.layer3.2.bn2.weight\", \"model.layer3.2.bn2.bias\", \"model.layer3.2.bn2.running_mean\", \"model.layer3.2.bn2.running_var\", \"model.layer3.2.bn2.num_batches_tracked\", \"model.layer3.2.conv3.weight\", \"model.layer3.2.bn3.weight\", \"model.layer3.2.bn3.bias\", \"model.layer3.2.bn3.running_mean\", \"model.layer3.2.bn3.running_var\", \"model.layer3.2.bn3.num_batches_tracked\", \"model.layer3.3.conv1.weight\", \"model.layer3.3.bn1.weight\", \"model.layer3.3.bn1.bias\", \"model.layer3.3.bn1.running_mean\", \"model.layer3.3.bn1.running_var\", \"model.layer3.3.bn1.num_batches_tracked\", \"model.layer3.3.conv2.weight\", \"model.layer3.3.bn2.weight\", \"model.layer3.3.bn2.bias\", \"model.layer3.3.bn2.running_mean\", \"model.layer3.3.bn2.running_var\", \"model.layer3.3.bn2.num_batches_tracked\", \"model.layer3.3.conv3.weight\", \"model.layer3.3.bn3.weight\", \"model.layer3.3.bn3.bias\", \"model.layer3.3.bn3.running_mean\", \"model.layer3.3.bn3.running_var\", \"model.layer3.3.bn3.num_batches_tracked\", \"model.layer3.4.conv1.weight\", \"model.layer3.4.bn1.weight\", \"model.layer3.4.bn1.bias\", \"model.layer3.4.bn1.running_mean\", \"model.layer3.4.bn1.running_var\", \"model.layer3.4.bn1.num_batches_tracked\", \"model.layer3.4.conv2.weight\", \"model.layer3.4.bn2.weight\", \"model.layer3.4.bn2.bias\", \"model.layer3.4.bn2.running_mean\", \"model.layer3.4.bn2.running_var\", \"model.layer3.4.bn2.num_batches_tracked\", \"model.layer3.4.conv3.weight\", \"model.layer3.4.bn3.weight\", \"model.layer3.4.bn3.bias\", \"model.layer3.4.bn3.running_mean\", \"model.layer3.4.bn3.running_var\", \"model.layer3.4.bn3.num_batches_tracked\", \"model.layer3.5.conv1.weight\", \"model.layer3.5.bn1.weight\", \"model.layer3.5.bn1.bias\", \"model.layer3.5.bn1.running_mean\", \"model.layer3.5.bn1.running_var\", \"model.layer3.5.bn1.num_batches_tracked\", \"model.layer3.5.conv2.weight\", \"model.layer3.5.bn2.weight\", \"model.layer3.5.bn2.bias\", \"model.layer3.5.bn2.running_mean\", \"model.layer3.5.bn2.running_var\", \"model.layer3.5.bn2.num_batches_tracked\", \"model.layer3.5.conv3.weight\", \"model.layer3.5.bn3.weight\", \"model.layer3.5.bn3.bias\", \"model.layer3.5.bn3.running_mean\", \"model.layer3.5.bn3.running_var\", \"model.layer3.5.bn3.num_batches_tracked\", \"model.layer3.0.conv3.weight\", \"model.layer3.0.bn3.weight\", \"model.layer3.0.bn3.bias\", \"model.layer3.0.bn3.running_mean\", \"model.layer3.0.bn3.running_var\", \"model.layer3.0.bn3.num_batches_tracked\", \"model.layer3.1.conv3.weight\", \"model.layer3.1.bn3.weight\", \"model.layer3.1.bn3.bias\", \"model.layer3.1.bn3.running_mean\", \"model.layer3.1.bn3.running_var\", \"model.layer3.1.bn3.num_batches_tracked\", \"model.layer4.2.conv1.weight\", \"model.layer4.2.bn1.weight\", \"model.layer4.2.bn1.bias\", \"model.layer4.2.bn1.running_mean\", \"model.layer4.2.bn1.running_var\", \"model.layer4.2.bn1.num_batches_tracked\", \"model.layer4.2.conv2.weight\", \"model.layer4.2.bn2.weight\", \"model.layer4.2.bn2.bias\", \"model.layer4.2.bn2.running_mean\", \"model.layer4.2.bn2.running_var\", \"model.layer4.2.bn2.num_batches_tracked\", \"model.layer4.2.conv3.weight\", \"model.layer4.2.bn3.weight\", \"model.layer4.2.bn3.bias\", \"model.layer4.2.bn3.running_mean\", \"model.layer4.2.bn3.running_var\", \"model.layer4.2.bn3.num_batches_tracked\", \"model.layer4.0.conv3.weight\", \"model.layer4.0.bn3.weight\", \"model.layer4.0.bn3.bias\", \"model.layer4.0.bn3.running_mean\", \"model.layer4.0.bn3.running_var\", \"model.layer4.0.bn3.num_batches_tracked\", \"model.layer4.1.conv3.weight\", \"model.layer4.1.bn3.weight\", \"model.layer4.1.bn3.bias\", \"model.layer4.1.bn3.running_mean\", \"model.layer4.1.bn3.running_var\", \"model.layer4.1.bn3.num_batches_tracked\", \"model.fc.1.weight\", \"model.fc.1.bias\". \n\tsize mismatch for model.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for model.layer2.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1, 1]).\n\tsize mismatch for model.layer2.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for model.layer2.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for model.layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for model.layer2.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for model.layer2.1.conv1.weight: copying a param with shape torch.Size([128, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for model.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for model.layer3.0.downsample.0.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 1, 1]).\n\tsize mismatch for model.layer3.0.downsample.1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.layer3.0.downsample.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.layer3.0.downsample.1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.layer3.1.conv1.weight: copying a param with shape torch.Size([256, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for model.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).\n\tsize mismatch for model.layer4.0.downsample.0.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for model.layer4.0.downsample.1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.layer4.0.downsample.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.layer4.0.downsample.1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.layer4.1.conv1.weight: copying a param with shape torch.Size([512, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import tempfile\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from typing import List\n",
    "\n",
    "# Define the CNN model for angle regression\n",
    "class AngleRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AngleRegressionModel, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 1)  # Regression output\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Function to load the pre-trained model\n",
    "def load_angle_regression_model(model_path: str):\n",
    "    model = AngleRegressionModel()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Function to predict the rotation angle of an image\n",
    "def predict_rotation_angle(model, image: 'Image') -> float:\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    image_tensor = preprocess(image).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "    angle = outputs.item()\n",
    "    return angle % 360\n",
    "\n",
    "# Function to convert a PDF page to an image\n",
    "def convert_pdf_page_to_image(page: 'PdfReader.PageObject') -> 'Image':\n",
    "    pdf_writer = PdfWriter()\n",
    "    pdf_writer.add_page(page)\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(suffix=\".pdf\", delete=False) as temp_pdf:\n",
    "        pdf_writer.write(temp_pdf)\n",
    "        temp_pdf_path = temp_pdf.name\n",
    "    \n",
    "    images = convert_from_path(temp_pdf_path, dpi=300)\n",
    "    os.remove(temp_pdf_path)\n",
    "    \n",
    "    return images[0]\n",
    "\n",
    "# Function to determine the exact rotation angle\n",
    "def determine_rotation_angle(model, page: 'PdfReader.PageObject') -> float:\n",
    "    page_image = convert_pdf_page_to_image(page)\n",
    "    rotation_angle = predict_rotation_angle(model, page_image)\n",
    "    return rotation_angle\n",
    "\n",
    "# Main function to rotate all pages upright\n",
    "def rotate_all_pages_upright(input_pdf: str, model_path: str) -> List[float]:\n",
    "    model = load_angle_regression_model(model_path)\n",
    "    reader = PdfReader(input_pdf)\n",
    "    angles = []\n",
    "    for page_number in range(len(reader.pages)):\n",
    "        current_page = reader.pages[page_number]\n",
    "        rotation_angle = determine_rotation_angle(model, current_page)\n",
    "        angles.append(rotation_angle)\n",
    "    return angles\n",
    "\n",
    "# Usage\n",
    "output_pdf = \"grouped_documents.pdf\"\n",
    "model_path = \"angle_regression_model.pth\"  # Path to your pre-trained model\n",
    "rotation_angles = rotate_all_pages_upright(output_pdf, model_path)\n",
    "print(f\"Rotation angles for each page: {rotation_angles}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05d5e856-e95d-43cd-8f26-50c47c587c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation angles for each page: [2.4669904708862305, 2.5704703330993652, 2.5704689025878906, 175.28688049316406, 172.16053771972656, 176.12037658691406, 20.410871505737305, 20.410871505737305, 20.410871505737305, 4.188563823699951, 4.191892147064209, 4.190777778625488, 20.410871505737305, 20.410871505737305, 20.410871505737305, 174.5769805908203, 172.40902709960938, 20.410871505737305]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import tempfile\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from typing import List\n",
    "\n",
    "# Define the CNN model for angle regression\n",
    "class AngleRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AngleRegressionModel, self).__init__()\n",
    "        self.model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.model.fc.in_features, 2)  # Predicting sine and cosine of the angle\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Function to load the pre-trained model\n",
    "def load_angle_regression_model(model_path: str):\n",
    "    model = AngleRegressionModel()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Function to convert sine and cosine to angle\n",
    "def vector_to_angle(vector):\n",
    "    angle_rad = torch.atan2(vector[1], vector[0])\n",
    "    angle_deg = torch.rad2deg(angle_rad)\n",
    "    return angle_deg if angle_deg >= 0 else angle_deg + 360\n",
    "\n",
    "# Function to predict the rotation angle of an image\n",
    "def predict_rotation_angle(model, image: 'Image') -> float:\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    image_tensor = preprocess(image).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        outputs = vector_to_angle(model(image_tensor)[0])\n",
    "    angle = outputs.item()\n",
    "    return angle % 360\n",
    "\n",
    "# Function to convert a PDF page to an image\n",
    "def convert_pdf_page_to_image(page: 'PdfReader.PageObject') -> 'Image':\n",
    "    pdf_writer = PdfWriter()\n",
    "    pdf_writer.add_page(page)\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(suffix=\".pdf\", delete=False) as temp_pdf:\n",
    "        pdf_writer.write(temp_pdf)\n",
    "        temp_pdf_path = temp_pdf.name\n",
    "    \n",
    "    images = convert_from_path(temp_pdf_path, dpi=300)\n",
    "    os.remove(temp_pdf_path)\n",
    "    \n",
    "    return images[0]\n",
    "\n",
    "# Function to determine the exact rotation angle\n",
    "def determine_rotation_angle(model, page: 'PdfReader.PageObject') -> float:\n",
    "    page_image = convert_pdf_page_to_image(page)\n",
    "    rotation_angle = predict_rotation_angle(model, page_image)\n",
    "    return rotation_angle\n",
    "\n",
    "# Main function to rotate all pages upright\n",
    "def rotate_all_pages_upright(input_pdf: str, model_path: str) -> List[float]:\n",
    "    model = load_angle_regression_model(model_path)\n",
    "    reader = PdfReader(input_pdf)\n",
    "    angles = []\n",
    "    for page_number in range(len(reader.pages)):\n",
    "        current_page = reader.pages[page_number]\n",
    "        rotation_angle = determine_rotation_angle(model, current_page)\n",
    "        angles.append(rotation_angle)\n",
    "    return angles\n",
    "\n",
    "# Usage\n",
    "output_pdf = \"grouped_documents.pdf\"\n",
    "model_path = \"angle_regression_model_3.pth\"  # Path to your pre-trained model\n",
    "rotation_angles = rotate_all_pages_upright(output_pdf, model_path)\n",
    "print(f\"Rotation angles for each page: {rotation_angles}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ec6a0-be0e-4f6a-b9ed-db2e8a98a17c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
